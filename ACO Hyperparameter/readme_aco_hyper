Оптимизация гиперпараметров регрессионной модели случайного леса с использованием муравьиного алгоритма

Аннотация

В данной работе представлено исследование по применению муравьиного алгоритма (ACO) для оптимизации гиперпараметров модели регрессии случайного леса. Целью исследования является минимизация среднеквадратичной ошибки (MSE) модели на заданном наборе данных путем автоматического подбора оптимальных значений гиперпараметров. Проведено экспериментальное исследование, демонстрирующее эффективность предложенного подхода.

1. Введение

Оптимизация гиперпараметров является критически важным этапом в процессе построения моделей машинного обучения, поскольку правильный выбор параметров существенно влияет на производительность модели. Ручной подбор гиперпараметров является трудоемким и не всегда эффективным, особенно для сложных моделей, таких как случайный лес, с большим количеством настраиваемых параметров. В связи с этим, автоматизация процесса оптимизации гиперпараметров представляет значительный интерес.

Муравьиный алгоритм (ACO) является метаэвристическим алгоритмом, вдохновленным поведением муравьев при поиске кратчайших путей. ACO успешно применяется для решения различных задач оптимизации, включая оптимизацию гиперпараметров моделей машинного обучения.

2. Материалы и методы

2.1. Набор данных

В качестве набора данных использовался синтетический набор данных, представленный в файле hyperparameter_data.csv. Набор данных был разделен на обучающую (80%) и тестовую (20%) выборки.

2.2. Модель регрессии случайного леса

В качестве модели регрессии использовалась модель случайного леса (Random Forest Regressor) из библиотеки scikit-learn. Оптимизации подвергались следующие гиперпараметры:

n_estimators: количество деревьев в лесу (диапазон: 50 – 500);
max_depth: максимальная глубина деревьев (диапазон: 3 – 15);
min_samples_split: минимальное количество объектов для разбиения узла (диапазон: 2 – 10);
min_samples_leaf: минимальное количество объектов в листовом узле (диапазон: 1 – 10).
2.3. Муравьиный алгоритм (ACO)

Для оптимизации гиперпараметров был реализован муравьиный алгоритм. Алгоритм включает следующие этапы:

Инициализация: случайное распределение муравьев по пространству гиперпараметров.
Конструирование решения: каждый муравей выбирает комбинацию гиперпараметров на основе вероятностного правила, учитывающего уровень феромонов.
Оценка решения: выбранная комбинация гиперпараметров используется для обучения модели случайного леса, и оценивается ее производительность с помощью среднеквадратичной ошибки (MSE) на тестовой выборке.
Обновление феромонов: уровень феромонов на путях, соответствующих лучшим решениям, увеличивается.
Испарение феромонов: уровень феромонов на всех путях уменьшается с заданным коэффициентом испарения (rho = 0.5).
Повторение шагов 2-5 до достижения заданного числа итераций (20 итераций).
3. Результаты

В результате выполнения алгоритма были получены оптимальные значения гиперпараметров, минимизирующие MSE. В таблице 1 представлены результаты работы алгоритма на протяжении 20 итераций.

Таблица 1: Результаты оптимизации гиперпараметров

Итерация	Лучший результат (MSE)
1	-0.123
2	-0.098
...	...
20	...
Лучшие найденные гиперпараметры: [400, 10, 3, 2].
